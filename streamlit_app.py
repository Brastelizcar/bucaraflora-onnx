# streamlit_app.py - VERSI√ìN CON INFORMACI√ìN DE FIREBASE
# Actualizado para mostrar informaci√≥n rica desde Firestore

import streamlit as st
import sys
from pathlib import Path
from PIL import Image
import numpy as np
from datetime import datetime
import json
import time

# ==================== CONFIGURACI√ìN DE LA P√ÅGINA ====================
st.set_page_config(
    page_title="üå± BucaraFlora - ONNX Runtime",
    page_icon="üå±",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ==================== CONFIGURACI√ìN SIMPLIFICADA ====================
CONFIG = {
    "onnx_model_path": "model/plant_classifier.onnx",
    "species_path": "model/species_list.json",
    "target_size": (224, 224),
    "max_file_size_mb": 10,
    "top_predictions": 5
}

# ==================== CSS PERSONALIZADO ====================
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
        color: #2E8B57;
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 1rem;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
    }
    
    .prediction-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #28a745;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .info-section {
        background: #ffffff;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e9ecef;
        margin: 0.5rem 0;
    }
    
    .confidence-bar {
        background: #e9ecef;
        border-radius: 10px;
        height: 20px;
        margin: 0.5rem 0;
        overflow: hidden;
    }
    
    .confidence-fill {
        background: linear-gradient(90deg, #28a745, #20c997);
        height: 100%;
        transition: width 0.3s ease;
    }
    
    .performance-badge {
        background: #17a2b8;
        color: white;
        padding: 0.25rem 0.5rem;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: bold;
    }
    
    .firebase-info {
        background: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ==================== FUNCIONES DE CARGA DEL MODELO ====================

@st.cache_resource
def load_onnx_model():
    """Carga el modelo ONNX - Ultra r√°pido y eficiente"""
    try:
        import onnxruntime as ort
        
        model_path = CONFIG["onnx_model_path"]
        
        if not Path(model_path).exists():
            st.error(f"‚ùå Modelo ONNX no encontrado: {model_path}")
            st.info("üí° Aseg√∫rate de ejecutar step2_convert_model.py primero")
            return None
        
        # Configurar sesi√≥n ONNX con optimizaciones
        session_options = ort.SessionOptions()
        session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        session = ort.InferenceSession(model_path, session_options)
        
        return session
        
    except ImportError:
        st.error("‚ùå ONNX Runtime no est√° instalado")
        st.info("üí° Instala con: pip install onnxruntime")
        return None
    except Exception as e:
        st.error(f"‚ùå Error cargando modelo ONNX: {e}")
        return None

@st.cache_data
def load_species_list():
    """Carga la lista de especies"""
    try:
        species_path = CONFIG["species_path"]
        
        if not Path(species_path).exists():
            st.error(f"‚ùå Lista de especies no encontrada: {species_path}")
            return []
        
        with open(species_path, 'r', encoding='utf-8') as f:
            species_list = json.load(f)
        
        return species_list
        
    except Exception as e:
        st.error(f"‚ùå Error cargando especies: {e}")
        return []

# ==================== NUEVA FUNCI√ìN: INFORMACI√ìN DE FIREBASE ====================

@st.cache_data(ttl=300)  # Cache por 5 minutos
# ==================== FIREBASE ARREGLADO PARA STREAMLIT ====================

def get_plant_info_from_firebase(species_name):
    """Obtiene informaci√≥n rica de la planta desde Firebase - VERSI√ìN ARREGLADA"""
    try:
        # Importar la nueva funci√≥n optimizada para Streamlit
        from utils.firebase_streamlit import get_plant_info_complete
        
        # Obtener informaci√≥n usando la funci√≥n optimizada
        plant_info = get_plant_info_complete(species_name)
        
        return plant_info
        
    except ImportError:
        st.warning("‚ö†Ô∏è Firebase Streamlit no est√° configurado")
        return {
            "found": False,
            "nombre_comun": "Especie identificada",
            "nombre_cientifico": species_name,
            "descripcion": "Esta especie est√° en nuestra base de datos de 335 plantas colombianas.",
            "familia": "",
            "origen": "",
            "fuente": "",
            "imagenes": [],
            "taxonomia": {},
            "fuente_datos": "Sin conexi√≥n Firebase"
        }
    except Exception as e:
        st.error(f"‚ùå Error obteniendo info de Firebase: {e}")
        return {
            "found": False,
            "nombre_comun": "Error al cargar informaci√≥n",
            "nombre_cientifico": species_name,
            "descripcion": f"Error conectando con la base de datos: {str(e)}",
            "familia": "",
            "origen": "",
            "fuente": "",
            "imagenes": [],
            "taxonomia": {},
            "fuente_datos": "Error"
        }

# ==================== FUNCIONES DE PROCESAMIENTO ====================

def preprocess_image(image):
    """Procesa la imagen para el modelo ONNX"""
    try:
        # Redimensionar manteniendo aspecto
        img = image.resize(CONFIG["target_size"], Image.Resampling.LANCZOS)
        
        # Convertir a array numpy y normalizar
        img_array = np.array(img, dtype=np.float32) / 255.0
        
        # Agregar dimensi√≥n batch
        img_array = np.expand_dims(img_array, axis=0)
        
        return img_array
        
    except Exception as e:
        st.error(f"‚ùå Error procesando imagen: {e}")
        return None

def predict_with_onnx(session, image_array, species_list, top_k=5):
    """Realiza predicci√≥n ultra-r√°pida con ONNX Runtime"""
    try:
        # Obtener nombres de entrada y salida
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name
        
        # Hacer predicci√≥n
        start_time = time.time()
        predictions = session.run([output_name], {input_name: image_array})[0][0]
        inference_time = time.time() - start_time
        
        # Obtener top-k √≠ndices
        top_indices = np.argsort(predictions)[::-1][:top_k]
        
        # Crear lista de resultados
        results = []
        for idx in top_indices:
            if idx < len(species_list):  # Verificar √≠ndice v√°lido
                results.append({
                    "species": species_list[idx],
                    "confidence": float(predictions[idx]),
                    "percentage": int(predictions[idx] * 100),
                    "index": int(idx)
                })
        
        return results, inference_time
        
    except Exception as e:
        st.error(f"‚ùå Error en predicci√≥n ONNX: {e}")
        return [], 0

def format_species_name(species_name):
    """Formatea nombre cient√≠fico para mostrar"""
    try:
        # Reemplazar guiones bajos con espacios
        formatted = species_name.replace('_', ' ')
        
        # Extraer g√©nero y especie
        parts = formatted.split(' ')
        if len(parts) >= 2:
            genus = parts[0]
            species_epithet = parts[1]
            
            # Si hay m√°s partes (autoridad, etc.), incluirlas
            if len(parts) > 2:
                authority = ' '.join(parts[2:])
                return f"*{genus} {species_epithet}* {authority}"
            else:
                # Solo g√©nero y especie
                return f"*{genus} {species_epithet}*"
        
        return formatted
    except:
        return species_name

def display_plant_information(plant_info):
    """Muestra informaci√≥n rica de la planta"""
    
    # T√≠tulo principal con nombre com√∫n
    st.markdown(f"### üåø {plant_info['nombre_comun']}")
    
    # Nombre cient√≠fico
    scientific_name = format_species_name(plant_info['nombre_cientifico'])
    st.markdown(f"**Nombre cient√≠fico:** {scientific_name}")
    
    # Informaci√≥n taxon√≥mica
    if plant_info['familia']:
        st.markdown(f"**Familia:** {plant_info['familia']}")
    
    # Descripci√≥n
    if plant_info['descripcion']:
        st.markdown(f"**Descripci√≥n:** {plant_info['descripcion']}")
    
    # Informaci√≥n adicional en secciones expandibles
    if plant_info['found']:
        # Taxonom√≠a completa
        taxonomia = plant_info.get('taxonomia', {})
        if taxonomia and any(taxonomia.values()):
            with st.expander("üî¨ Clasificaci√≥n taxon√≥mica"):
                cols = st.columns(2)
                
                with cols[0]:
                    if taxonomia.get('reino'):
                        st.write(f"**Reino:** {taxonomia['reino']}")
                    if taxonomia.get('filo'):
                        st.write(f"**Filo:** {taxonomia['filo']}")
                    if taxonomia.get('clase'):
                        st.write(f"**Clase:** {taxonomia['clase']}")
                    if taxonomia.get('orden'):
                        st.write(f"**Orden:** {taxonomia['orden']}")
                
                with cols[1]:
                    if taxonomia.get('familia'):
                        st.write(f"**Familia:** {taxonomia['familia']}")
                    if taxonomia.get('genero'):
                        st.write(f"**G√©nero:** {taxonomia['genero']}")
                    if taxonomia.get('especie'):
                        st.write(f"**Especie:** {taxonomia['especie']}")
        
        # Informaci√≥n adicional
        if plant_info.get('origen') or plant_info.get('fuente'):
            with st.expander("üìã Informaci√≥n adicional"):
                if plant_info.get('origen'):
                    st.write(f"**Fecha de observaci√≥n:** {plant_info['origen']}")
                if plant_info.get('fuente'):
                    st.write(f"**Fuente:** {plant_info['fuente']}")
    
    # Badge de fuente de datos
    fuente_color = "#28a745" if plant_info['found'] else "#6c757d"
    st.markdown(f"""
    <div style="text-align: right; margin-top: 1rem;">
        <span style="background: {fuente_color}; color: white; padding: 0.25rem 0.5rem; 
                     border-radius: 12px; font-size: 0.75rem;">
            üìä {plant_info['fuente_datos']}
        </span>
    </div>
    """, unsafe_allow_html=True)

# ==================== INTERFAZ PRINCIPAL ====================

def show_performance_info(inference_time):
    """Muestra informaci√≥n de rendimiento"""
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"""
        <div class="performance-badge">
            ‚ö° {inference_time*1000:.1f}ms
        </div>
        """, unsafe_allow_html=True)
        st.caption("Tiempo de inferencia")
    
    with col2:
        st.markdown(f"""
        <div class="performance-badge">
            üöÄ ONNX Runtime
        </div>
        """, unsafe_allow_html=True)
        st.caption("Motor de IA")
    
    with col3:
        st.markdown(f"""
        <div class="performance-badge">
            üåø 335 especies
        </div>
        """, unsafe_allow_html=True)
        st.caption("Base de datos")

def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    
    # Header principal
    st.markdown('<h1 class="main-header">üå± BucaraFlora - IA con Firebase</h1>', 
                unsafe_allow_html=True)
    
    st.markdown("""
    <div style="text-align: center; margin-bottom: 2rem;">
        <p style="font-size: 1.1rem; color: #666; margin-bottom: 1rem;">
            <strong>Identificador de plantas con informaci√≥n rica desde Firebase</strong>
        </p>
        <span class="performance-badge">üî• Powered by ONNX Runtime + Firebase Firestore</span>
    </div>
    """, unsafe_allow_html=True)
    
    # Cargar modelo y especies
    with st.spinner("üîÑ Cargando modelo optimizado..."):
        session = load_onnx_model()
        species_list = load_species_list()
    
    # Verificar que todo est√© cargado
    if session is None:
        st.error("‚ùå No se pudo cargar el modelo ONNX")
        st.info("üí° Ejecuta step2_convert_model.py para generar el modelo ONNX")
        return
    
    if not species_list:
        st.error("‚ùå No se pudo cargar la lista de especies")
        return
    
    # Mostrar estado del sistema
    st.success(f"‚úÖ Sistema listo: Modelo ONNX cargado con {len(species_list)} especies")
    
    # Test de Firebase en sidebar
    with st.sidebar:
        st.markdown("### üî• Estado Firebase")
        try:
            from utils.firebase_streamlit import initialize_firebase
        
        # Verificar conexi√≥n usando nuestra funci√≥n optimizada
            db = initialize_firebase()
        
            if db:
                st.markdown("üü¢ **Conectado**")
                st.markdown("Proyecto: `bucaraflora-f0161`")
                st.markdown("Colecci√≥n: `planta`")
            else:
                st.markdown("üî¥ **Error de conexi√≥n**")
            
        except Exception as e:
            st.markdown("üü° **Error en verificaci√≥n**")
            st.caption(f"Error: {str(e)[:50]}...")
        
        st.markdown("### ü§ñ Informaci√≥n del Modelo")
        st.markdown("- **Motor:** ONNX Runtime")
        st.markdown("- **Especies:** 335")
        st.markdown("- **Precisi√≥n:** Id√©ntica a TensorFlow")
        st.markdown("- **Velocidad:** 100x+ m√°s r√°pido")
        st.markdown("- **Tama√±o:** 55% m√°s peque√±o")
        st.markdown("- **Python:** 3.13 compatible ‚úÖ")
    
    # √Årea principal de upload
    st.markdown("### üì∏ Sube una foto de tu planta")
    
    uploaded_file = st.file_uploader(
        "Selecciona una imagen",
        type=['jpg', 'jpeg', 'png'],
        help=f"Formatos: JPG, JPEG, PNG. M√°ximo {CONFIG['max_file_size_mb']}MB."
    )
    
    if uploaded_file is not None:
        # Validar tama√±o
        if uploaded_file.size > CONFIG['max_file_size_mb'] * 1024 * 1024:
            st.error(f"‚ùå Archivo muy grande. M√°ximo {CONFIG['max_file_size_mb']}MB.")
            return
        
        try:
            # Cargar y mostrar imagen
            image = Image.open(uploaded_file).convert('RGB')
            
            # Mostrar imagen centrada
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(image, caption="Tu planta", use_container_width=True)
            
            # Bot√≥n de an√°lisis
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("üîç Identificar con IA", type="primary", use_container_width=True):
                    
                    with st.spinner("üß† Analizando con IA ultra-r√°pida..."):
                        # Procesar imagen
                        processed_image = preprocess_image(image)
                        
                        if processed_image is not None:
                            # Hacer predicci√≥n
                            predictions, inference_time = predict_with_onnx(
                                session, processed_image, species_list, 
                                top_k=CONFIG['top_predictions']
                            )
                            
                            if predictions:
                                # Mostrar informaci√≥n de rendimiento
                                show_performance_info(inference_time)
                                
                                # Resultado principal
                                best_prediction = predictions[0]
                                
                                st.markdown('<div class="prediction-card">', unsafe_allow_html=True)
                                
                                # ===== NUEVA FUNCIONALIDAD: INFORMACI√ìN DE FIREBASE =====
                                with st.spinner("üî• Obteniendo informaci√≥n desde Firebase..."):
                                    plant_info = get_plant_info_from_firebase(best_prediction['species'])
                                
                                # Mostrar informaci√≥n rica de la planta
                                display_plant_information(plant_info)
                                
                                # Barra de confianza visual
                                confidence_pct = best_prediction['percentage']
                                st.markdown(f"""
                                <div class="confidence-bar">
                                    <div class="confidence-fill" style="width: {confidence_pct}%;"></div>
                                </div>
                                <p style="text-align: center; font-weight: bold; margin: 0.5rem 0;">
                                    Confianza: {confidence_pct}%
                                </p>
                                """, unsafe_allow_html=True)
                                
                                st.markdown('</div>', unsafe_allow_html=True)
                                
                                # Mostrar alternativas si hay m√°s predicciones
                                if len(predictions) > 1:
                                    st.markdown("### ü§î Otras posibilidades:")
                                    
                                    for i, pred in enumerate(predictions[1:], 2):
                                        # Obtener informaci√≥n de Firebase para alternativas
                                        alt_info = get_plant_info_from_firebase(pred['species'])
                                        
                                        with st.expander(f"{i}. {alt_info['nombre_comun']} - {pred['percentage']}%"):
                                            st.markdown(f"**Nombre cient√≠fico:** {format_species_name(alt_info['nombre_cientifico'])}")
                                            st.markdown(f"**Confianza:** {pred['percentage']}%")
                                            if alt_info['familia']:
                                                st.markdown(f"**Familia:** {alt_info['familia']}")
                                            st.markdown(f"**Descripci√≥n:** {alt_info['descripcion'][:200]}...")
                                
                                # Mensaje de √©xito
                                st.success("üéâ ¬°Identificaci√≥n completada con informaci√≥n de Firebase!")
                                st.balloons()
                                
                                # Informaci√≥n t√©cnica
                                with st.expander("üìä Informaci√≥n t√©cnica"):
                                    st.markdown(f"- **Tiempo de inferencia:** {inference_time*1000:.2f}ms")
                                    st.markdown(f"- **Motor de IA:** ONNX Runtime")
                                    st.markdown(f"- **Base de datos:** Firebase Firestore")
                                    st.markdown(f"- **Modelo:** 335 especies colombianas")
                                    st.markdown(f"- **Arquitectura:** MobileNetV2 optimizada")
                                    st.markdown(f"- **Index de clase:** {best_prediction['index']}")
                                    st.markdown(f"- **Informaci√≥n encontrada:** {'‚úÖ S√≠' if plant_info['found'] else '‚ùå No'}")
                                
                                # Bot√≥n para nueva consulta
                                if st.button("üîÑ Identificar otra planta", use_container_width=True):
                                    st.rerun()
                                
                            else:
                                st.error("‚ùå No se pudo realizar la predicci√≥n")
                        else:
                            st.error("‚ùå Error procesando la imagen")
                            
        except Exception as e:
            st.error(f"‚ùå Error cargando imagen: {e}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; font-size: 0.9rem;">
        üå± BucaraFlora - Identificador de Plantas con IA<br>
        üî• Optimizado con ONNX Runtime + Firebase Firestore
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()